{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Financial Sentiment Analysis\nIn this notebook I did Financial Sentiment Analysis by using different models\n- First, Classification Models: Naive Bayes Classification Model\n- Then, Sequential Models: RNN, LSTM, GRU\n- Finally, Transformers: Bert\n\nBy the end of the notebook there's a comparison between results of each model","metadata":{}},{"cell_type":"code","source":"# Essentials\nimport numpy as np\nimport pandas as pd \nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport os\n\n# Import functions for data preprocessing & data preparation\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.utils import resample\nfrom sklearn.feature_extraction.text import CountVectorizer\n\nfrom nltk.tokenize import word_tokenize\nfrom nltk.stem import WordNetLemmatizer\nfrom nltk.stem import PorterStemmer, LancasterStemmer\nfrom nltk.stem.snowball import SnowballStemmer\nfrom nltk.corpus import stopwords\nfrom nltk.corpus import wordnet\nimport string\nfrom string import punctuation\nimport nltk\nimport re\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"execution":{"iopub.status.busy":"2022-07-04T23:59:48.391609Z","iopub.execute_input":"2022-07-04T23:59:48.391883Z","iopub.status.idle":"2022-07-04T23:59:48.409421Z","shell.execute_reply.started":"2022-07-04T23:59:48.391859Z","shell.execute_reply":"2022-07-04T23:59:48.407601Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"nltk.download('punkt')\nnltk.download('stopwords')","metadata":{"execution":{"iopub.status.busy":"2022-07-04T23:59:49.535935Z","iopub.execute_input":"2022-07-04T23:59:49.537844Z","iopub.status.idle":"2022-07-04T23:59:49.88354Z","shell.execute_reply.started":"2022-07-04T23:59:49.537795Z","shell.execute_reply":"2022-07-04T23:59:49.882591Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 1) Reading Data","metadata":{}},{"cell_type":"code","source":"data = pd.read_csv(\"../input/financial-sentiment-analysis/data.csv\")\ndata.head()","metadata":{"execution":{"iopub.status.busy":"2022-07-04T23:59:50.973493Z","iopub.execute_input":"2022-07-04T23:59:50.974186Z","iopub.status.idle":"2022-07-04T23:59:51.020386Z","shell.execute_reply.started":"2022-07-04T23:59:50.974136Z","shell.execute_reply":"2022-07-04T23:59:51.019389Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data['Sentiment'].value_counts().plot(kind='bar',figsize=(10,6),grid='-')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-04T23:59:51.587842Z","iopub.execute_input":"2022-07-04T23:59:51.588769Z","iopub.status.idle":"2022-07-04T23:59:51.882531Z","shell.execute_reply.started":"2022-07-04T23:59:51.588725Z","shell.execute_reply":"2022-07-04T23:59:51.881605Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data['Sentiment'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-07-04T23:59:52.032688Z","iopub.execute_input":"2022-07-04T23:59:52.033102Z","iopub.status.idle":"2022-07-04T23:59:52.046602Z","shell.execute_reply.started":"2022-07-04T23:59:52.033068Z","shell.execute_reply":"2022-07-04T23:59:52.045483Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> It seems that data is not balanced","metadata":{}},{"cell_type":"markdown","source":"## 2) Preprocessing","metadata":{}},{"cell_type":"markdown","source":"### 2.1) Data Cleaning","metadata":{}},{"cell_type":"code","source":"stop_words = stopwords.words('english')\nporter_stemmer = PorterStemmer()\nlancaster_stemmer = LancasterStemmer() \nsnowball_stemer = SnowballStemmer(language=\"english\")\nlzr = WordNetLemmatizer()","metadata":{"execution":{"iopub.status.busy":"2022-07-04T23:59:53.959046Z","iopub.execute_input":"2022-07-04T23:59:53.959404Z","iopub.status.idle":"2022-07-04T23:59:53.967854Z","shell.execute_reply.started":"2022-07-04T23:59:53.959371Z","shell.execute_reply":"2022-07-04T23:59:53.966838Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def text_processing(text):   \n    # convert text into lowercase\n    text = text.lower()\n\n    # remove new line characters in text\n    text = re.sub(r'\\n',' ', text)\n    \n    # remove punctuations from text\n    text = re.sub('[%s]' % re.escape(punctuation), \"\", text)\n    \n    # remove references and hashtags from text\n    text = re.sub(\"^a-zA-Z0-9$,.\", \"\", text)\n    \n    # remove multiple spaces from text\n    text = re.sub(r'\\s+', ' ', text, flags=re.I)\n    \n    # remove special characters from text\n    text = re.sub(r'\\W', ' ', text)\n    \n    # tokenize the words using nltk word tokenizer and remove the stop words using nltk package's english stop words\n    text = ' '.join([word for word in word_tokenize(text) if word not in stop_words])\n    \n    # stemming using porter stemmer from nltk package - msh a7sn 7aga - momken: lancaster, snowball\n    # text=' '.join([porter_stemmer.stem(word) for word in word_tokenize(text)])\n    # text=' '.join([lancaster_stemmer.stem(word) for word in word_tokenize(text)])\n    # text=' '.join([snowball_stemer.stem(word) for word in word_tokenize(text)])\n    \n    # lemmatizer using WordNetLemmatizer from nltk package\n    text=' '.join([lzr.lemmatize(word) for word in word_tokenize(text)])\n\n    return text","metadata":{"execution":{"iopub.status.busy":"2022-07-04T23:59:54.393209Z","iopub.execute_input":"2022-07-04T23:59:54.393577Z","iopub.status.idle":"2022-07-04T23:59:54.401381Z","shell.execute_reply.started":"2022-07-04T23:59:54.393522Z","shell.execute_reply":"2022-07-04T23:59:54.400314Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_copy = data.copy()\ndata_copy.Sentence = data_copy.Sentence.apply(lambda text: text_processing(text))","metadata":{"execution":{"iopub.status.busy":"2022-07-04T23:59:55.322782Z","iopub.execute_input":"2022-07-04T23:59:55.323713Z","iopub.status.idle":"2022-07-05T00:00:00.352308Z","shell.execute_reply.started":"2022-07-04T23:59:55.323666Z","shell.execute_reply":"2022-07-05T00:00:00.351282Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"le = LabelEncoder()\ndata_copy['Sentiment'] = le.fit_transform(data_copy['Sentiment'])","metadata":{"execution":{"iopub.status.busy":"2022-07-05T00:00:00.354218Z","iopub.execute_input":"2022-07-05T00:00:00.354583Z","iopub.status.idle":"2022-07-05T00:00:00.362089Z","shell.execute_reply.started":"2022-07-05T00:00:00.354536Z","shell.execute_reply":"2022-07-05T00:00:00.360963Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"processed_data = {\n    'Sentence':data_copy.Sentence,\n    'Sentiment':data_copy['Sentiment']\n}\n\nprocessed_data = pd.DataFrame(processed_data)\nprocessed_data.head()","metadata":{"execution":{"iopub.status.busy":"2022-07-05T00:00:00.363614Z","iopub.execute_input":"2022-07-05T00:00:00.364226Z","iopub.status.idle":"2022-07-05T00:00:00.38445Z","shell.execute_reply.started":"2022-07-05T00:00:00.364153Z","shell.execute_reply":"2022-07-05T00:00:00.383581Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"processed_data['Sentiment'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-07-05T00:01:19.574264Z","iopub.execute_input":"2022-07-05T00:01:19.574796Z","iopub.status.idle":"2022-07-05T00:01:19.589032Z","shell.execute_reply.started":"2022-07-05T00:01:19.574748Z","shell.execute_reply":"2022-07-05T00:01:19.587599Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 2.2) Data Resampling\nSince, Data is not balanced we need to do resampling to get balanced data","metadata":{}},{"cell_type":"code","source":"df_neutral = processed_data[(processed_data['Sentiment']==1)] \ndf_negative = processed_data[(processed_data['Sentiment']==0)]\ndf_positive = processed_data[(processed_data['Sentiment']==2)]\n\n# upsample minority classes\ndf_negative_upsampled = resample(df_negative, \n                                 replace=True,    \n                                 n_samples= 3130, \n                                 random_state=42)  \n\ndf_positive_upsampled = resample(df_positive, \n                                 replace=True,    \n                                 n_samples= 3130, \n                                 random_state=42)  \n\n\n# Concatenate the upsampled dataframes with the neutral dataframe\nfinal_data = pd.concat([df_negative_upsampled,df_neutral,df_positive_upsampled])","metadata":{"execution":{"iopub.status.busy":"2022-07-05T00:01:34.385926Z","iopub.execute_input":"2022-07-05T00:01:34.386263Z","iopub.status.idle":"2022-07-05T00:01:34.400245Z","shell.execute_reply.started":"2022-07-05T00:01:34.386233Z","shell.execute_reply":"2022-07-05T00:01:34.399311Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_data['Sentiment'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-07-05T00:01:42.58774Z","iopub.execute_input":"2022-07-05T00:01:42.588346Z","iopub.status.idle":"2022-07-05T00:01:42.597024Z","shell.execute_reply.started":"2022-07-05T00:01:42.588305Z","shell.execute_reply":"2022-07-05T00:01:42.595916Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3. Classification with Classifier Model (Naive Bayes)","metadata":{}},{"cell_type":"markdown","source":"### 3.1) Data Transformation","metadata":{}},{"cell_type":"code","source":"corpus = []\nfor sentence in final_data['Sentence']:\n    corpus.append(sentence)\ncorpus[0:5]","metadata":{"execution":{"iopub.status.busy":"2022-07-05T02:11:41.296996Z","iopub.execute_input":"2022-07-05T02:11:41.297749Z","iopub.status.idle":"2022-07-05T02:11:41.312753Z","shell.execute_reply.started":"2022-07-05T02:11:41.297702Z","shell.execute_reply":"2022-07-05T02:11:41.311582Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.feature_extraction.text import CountVectorizer","metadata":{"execution":{"iopub.status.busy":"2022-07-05T02:11:42.806512Z","iopub.execute_input":"2022-07-05T02:11:42.807181Z","iopub.status.idle":"2022-07-05T02:11:42.811912Z","shell.execute_reply.started":"2022-07-05T02:11:42.807146Z","shell.execute_reply":"2022-07-05T02:11:42.810759Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cv = CountVectorizer(max_features=1500)","metadata":{"execution":{"iopub.status.busy":"2022-07-05T02:11:44.823045Z","iopub.execute_input":"2022-07-05T02:11:44.823425Z","iopub.status.idle":"2022-07-05T02:11:44.828555Z","shell.execute_reply.started":"2022-07-05T02:11:44.823393Z","shell.execute_reply":"2022-07-05T02:11:44.827528Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = cv.fit_transform(corpus).toarray()\ny = final_data.iloc[:, -1].values","metadata":{"execution":{"iopub.status.busy":"2022-07-05T02:11:46.459214Z","iopub.execute_input":"2022-07-05T02:11:46.459938Z","iopub.status.idle":"2022-07-05T02:11:46.687074Z","shell.execute_reply.started":"2022-07-05T02:11:46.45989Z","shell.execute_reply":"2022-07-05T02:11:46.686036Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 3.2) Dividing data into train and test","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split","metadata":{"execution":{"iopub.status.busy":"2022-07-05T02:11:53.642157Z","iopub.execute_input":"2022-07-05T02:11:53.642509Z","iopub.status.idle":"2022-07-05T02:11:53.647653Z","shell.execute_reply.started":"2022-07-05T02:11:53.642478Z","shell.execute_reply":"2022-07-05T02:11:53.645999Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)","metadata":{"execution":{"iopub.status.busy":"2022-07-05T02:12:07.363124Z","iopub.execute_input":"2022-07-05T02:12:07.363471Z","iopub.status.idle":"2022-07-05T02:12:07.410937Z","shell.execute_reply.started":"2022-07-05T02:12:07.363442Z","shell.execute_reply":"2022-07-05T02:12:07.409872Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 3.3) Model fitting","metadata":{}},{"cell_type":"code","source":"from sklearn.naive_bayes import GaussianNB","metadata":{"execution":{"iopub.status.busy":"2022-07-05T02:12:18.179604Z","iopub.execute_input":"2022-07-05T02:12:18.179952Z","iopub.status.idle":"2022-07-05T02:12:18.18778Z","shell.execute_reply.started":"2022-07-05T02:12:18.179925Z","shell.execute_reply":"2022-07-05T02:12:18.186765Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"classifier = GaussianNB()\nclassifier.fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2022-07-05T02:12:19.326404Z","iopub.execute_input":"2022-07-05T02:12:19.327093Z","iopub.status.idle":"2022-07-05T02:12:19.481584Z","shell.execute_reply.started":"2022-07-05T02:12:19.327048Z","shell.execute_reply":"2022-07-05T02:12:19.480604Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 3.4) Model Evaluation","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix, accuracy_score\ny_pred = classifier.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2022-07-05T02:12:24.168051Z","iopub.execute_input":"2022-07-05T02:12:24.168392Z","iopub.status.idle":"2022-07-05T02:12:24.265444Z","shell.execute_reply.started":"2022-07-05T02:12:24.168363Z","shell.execute_reply":"2022-07-05T02:12:24.264415Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cm = confusion_matrix(y_test, y_pred)\ncm","metadata":{"execution":{"iopub.status.busy":"2022-07-05T02:12:25.991115Z","iopub.execute_input":"2022-07-05T02:12:25.991458Z","iopub.status.idle":"2022-07-05T02:12:26.000399Z","shell.execute_reply.started":"2022-07-05T02:12:25.991428Z","shell.execute_reply":"2022-07-05T02:12:25.999468Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"nb_score = accuracy_score(y_test, y_pred)\nnb_score","metadata":{"execution":{"iopub.status.busy":"2022-07-05T02:12:43.18336Z","iopub.execute_input":"2022-07-05T02:12:43.183721Z","iopub.status.idle":"2022-07-05T02:12:43.191002Z","shell.execute_reply.started":"2022-07-05T02:12:43.183688Z","shell.execute_reply":"2022-07-05T02:12:43.189974Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 4) RNN, LSTM, GRU","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.layers import Embedding\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.preprocessing.text import one_hot\nfrom tensorflow.keras.layers import LSTM, SimpleRNN, GRU\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.layers import Bidirectional\nfrom tensorflow.keras.layers import Dropout, SpatialDropout1D\nfrom tensorflow.keras.preprocessing.text import Tokenizer","metadata":{"execution":{"iopub.status.busy":"2022-07-05T01:48:54.832319Z","iopub.execute_input":"2022-07-05T01:48:54.832712Z","iopub.status.idle":"2022-07-05T01:48:54.84382Z","shell.execute_reply.started":"2022-07-05T01:48:54.832677Z","shell.execute_reply":"2022-07-05T01:48:54.842859Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 4.1) Data Preparation","metadata":{}},{"cell_type":"code","source":"# The maximum number of words to be used. (most frequent)\nMAX_NB_WORDS = 50000\n# Max number of words in each complaint.\nMAX_SEQUENCE_LENGTH = 250\nEMBEDDING_DIM = 100","metadata":{"execution":{"iopub.status.busy":"2022-07-05T01:48:57.714733Z","iopub.execute_input":"2022-07-05T01:48:57.715084Z","iopub.status.idle":"2022-07-05T01:48:57.720025Z","shell.execute_reply.started":"2022-07-05T01:48:57.715055Z","shell.execute_reply":"2022-07-05T01:48:57.719005Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer = Tokenizer(num_words=MAX_NB_WORDS, filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~', lower=True)\ntokenizer.fit_on_texts(final_data['Sentence'].values)\nword_index = tokenizer.word_index\nprint('Found %s unique tokens.' % len(word_index))","metadata":{"execution":{"iopub.status.busy":"2022-07-05T01:48:59.576681Z","iopub.execute_input":"2022-07-05T01:48:59.577607Z","iopub.status.idle":"2022-07-05T01:48:59.748401Z","shell.execute_reply.started":"2022-07-05T01:48:59.577527Z","shell.execute_reply":"2022-07-05T01:48:59.746895Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_final = tokenizer.texts_to_sequences(final_data['Sentence'].values)\nX_final = pad_sequences(X_final, maxlen=MAX_SEQUENCE_LENGTH)\nprint('Shape of data tensor:', X_final.shape)","metadata":{"execution":{"iopub.status.busy":"2022-07-05T01:49:01.416254Z","iopub.execute_input":"2022-07-05T01:49:01.416625Z","iopub.status.idle":"2022-07-05T01:49:01.591349Z","shell.execute_reply.started":"2022-07-05T01:49:01.416593Z","shell.execute_reply":"2022-07-05T01:49:01.590259Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Y_final = pd.get_dummies(final_data['Sentiment']).values\nprint('Shape of label tensor:', Y_final.shape)","metadata":{"execution":{"iopub.status.busy":"2022-07-05T01:49:02.812188Z","iopub.execute_input":"2022-07-05T01:49:02.812756Z","iopub.status.idle":"2022-07-05T01:49:02.821168Z","shell.execute_reply.started":"2022-07-05T01:49:02.812716Z","shell.execute_reply":"2022-07-05T01:49:02.820176Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 4.2) Dividing data into train and test","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, Y_train, Y_test = train_test_split(X_final, Y_final, test_size = 0.3, random_state = 42, shuffle=True)\nprint(X_train.shape,Y_train.shape)\nprint(X_test.shape,Y_test.shape)","metadata":{"execution":{"iopub.status.busy":"2022-07-05T01:50:28.893579Z","iopub.execute_input":"2022-07-05T01:50:28.894555Z","iopub.status.idle":"2022-07-05T01:50:28.910283Z","shell.execute_reply.started":"2022-07-05T01:50:28.894496Z","shell.execute_reply":"2022-07-05T01:50:28.909272Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 4.3) Model Training","metadata":{}},{"cell_type":"markdown","source":"#### 4.3.1) RNN","metadata":{}},{"cell_type":"code","source":"rnn_model = Sequential()\nrnn_model.add(Embedding(MAX_NB_WORDS, EMBEDDING_DIM, input_length=X_final.shape[1]))\nrnn_model.add(SpatialDropout1D(0.2))\nrnn_model.add(SimpleRNN(128, dropout=0.2, recurrent_dropout=0.2))\nrnn_model.add(Dense(3, activation='softmax'))\nrnn_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n\nepochs = 5\nbatch_size = 64\n\nrnn_history = rnn_model.fit(X_train, Y_train, epochs=epochs, batch_size=batch_size,validation_split=0.2)","metadata":{"execution":{"iopub.status.busy":"2022-07-05T01:50:32.231052Z","iopub.execute_input":"2022-07-05T01:50:32.231704Z","iopub.status.idle":"2022-07-05T01:53:26.674085Z","shell.execute_reply.started":"2022-07-05T01:50:32.231665Z","shell.execute_reply":"2022-07-05T01:53:26.673125Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 4.3.1) LSTM","metadata":{}},{"cell_type":"code","source":"lstm_model = Sequential()\nlstm_model.add(Embedding(MAX_NB_WORDS, EMBEDDING_DIM, input_length=X_final.shape[1]))\nlstm_model.add(SpatialDropout1D(0.2))\nlstm_model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\nlstm_model.add(Dense(3, activation='softmax'))\nlstm_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n\nepochs = 5\nbatch_size = 64\n\nlstm_history = lstm_model.fit(X_train, Y_train, epochs=epochs, batch_size=batch_size,validation_split=0.2)","metadata":{"execution":{"iopub.status.busy":"2022-07-05T01:53:26.676805Z","iopub.execute_input":"2022-07-05T01:53:26.677145Z","iopub.status.idle":"2022-07-05T02:02:02.856683Z","shell.execute_reply.started":"2022-07-05T01:53:26.67711Z","shell.execute_reply":"2022-07-05T02:02:02.85572Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 4.3.1) GRU","metadata":{}},{"cell_type":"code","source":"gru_model = Sequential()\ngru_model.add(Embedding(MAX_NB_WORDS, EMBEDDING_DIM, input_length=X_final.shape[1]))\ngru_model.add(SpatialDropout1D(0.2))\ngru_model.add(GRU(128, dropout=0.2, recurrent_dropout=0.2))\ngru_model.add(Dense(3, activation='softmax'))\ngru_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n\nepochs = 5\nbatch_size = 64\n\ngru_history = gru_model.fit(X_train, Y_train, epochs=epochs, batch_size=batch_size,validation_split=0.2)","metadata":{"execution":{"iopub.status.busy":"2022-07-05T02:02:02.8589Z","iopub.execute_input":"2022-07-05T02:02:02.859294Z","iopub.status.idle":"2022-07-05T02:10:26.888941Z","shell.execute_reply.started":"2022-07-05T02:02:02.859256Z","shell.execute_reply":"2022-07-05T02:10:26.887586Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 4.4) Model Evaluation","metadata":{}},{"cell_type":"code","source":"rnn_accuracy = rnn_model.evaluate(X_test,Y_test)\nprint('RNN Model Evaluation\\n Loss: {:0.3f}\\n Accuracy: {:0.3f}'.format(rnn_accuracy[0],rnn_accuracy[1]))","metadata":{"execution":{"iopub.status.busy":"2022-07-05T02:10:26.892Z","iopub.execute_input":"2022-07-05T02:10:26.892637Z","iopub.status.idle":"2022-07-05T02:10:29.487261Z","shell.execute_reply.started":"2022-07-05T02:10:26.892595Z","shell.execute_reply":"2022-07-05T02:10:29.486127Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lstm_accuracy = lstm_model.evaluate(X_test,Y_test)\nprint('LSTM Model Evaluation\\n Loss: {:0.3f}\\n Accuracy: {:0.3f}'.format(lstm_accuracy[0],lstm_accuracy[1]))","metadata":{"execution":{"iopub.status.busy":"2022-07-05T02:10:29.488802Z","iopub.execute_input":"2022-07-05T02:10:29.489284Z","iopub.status.idle":"2022-07-05T02:10:35.984399Z","shell.execute_reply.started":"2022-07-05T02:10:29.489244Z","shell.execute_reply":"2022-07-05T02:10:35.983337Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gru_accuracy = gru_model.evaluate(X_test,Y_test)\nprint('GRU Model Evaluation\\n Loss: {:0.3f}\\n Accuracy: {:0.3f}'.format(gru_accuracy[0],gru_accuracy[1]))","metadata":{"execution":{"iopub.status.busy":"2022-07-05T02:10:35.986284Z","iopub.execute_input":"2022-07-05T02:10:35.986681Z","iopub.status.idle":"2022-07-05T02:10:42.267087Z","shell.execute_reply.started":"2022-07-05T02:10:35.986643Z","shell.execute_reply":"2022-07-05T02:10:42.265969Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 4.5) Plotting Results","metadata":{}},{"cell_type":"code","source":"# def get_plot(trained_model):\n#     accuracy=trained_model.history['accuracy']\n#     loss=trained_model.history['loss']\n#     val_accuracy=trained_model.history['val_accuracy']\n#     val_loss=trained_model.history['val_loss']\n#     epochs=[i for i in range(1,6)]\n\n#     plt.figure(figsize=(12,8))\n#     plt.plot(epochs,accuracy,'r',label='Training')\n#     plt.plot(epochs,val_accuracy,'--',label='Validation')\n#     plt.legend()\n#     plt.xlabel('Epochs')\n#     plt.ylabel('Accuracy')\n#     plt.title('Accuracy',fontsize=15)\n#     plt.grid()\n#     plt.show()\n\n#     plt.figure(figsize=(12,8))\n#     plt.plot(epochs,loss,'r',label='Training')\n#     plt.plot(epochs,val_loss,'--',label='Validation')\n#     plt.legend()\n#     plt.title('Loss',fontsize=15)\n#     plt.xlabel('Epochs')\n#     plt.ylabel('Loss')\n#     plt.grid()\n#     plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-04T19:15:17.750252Z","iopub.execute_input":"2022-07-04T19:15:17.750632Z","iopub.status.idle":"2022-07-04T19:15:17.760914Z","shell.execute_reply.started":"2022-07-04T19:15:17.750599Z","shell.execute_reply":"2022-07-04T19:15:17.759767Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## BERT","metadata":{}},{"cell_type":"code","source":"from transformers import AutoTokenizer, TFBertModel\n\nbert_tokenizer = AutoTokenizer.from_pretrained(\"bert-large-uncased\")\nbert_model = TFBertModel.from_pretrained(\"bert-large-uncased\")","metadata":{"execution":{"iopub.status.busy":"2022-07-05T00:02:18.046307Z","iopub.execute_input":"2022-07-05T00:02:18.046724Z","iopub.status.idle":"2022-07-05T00:04:25.564073Z","shell.execute_reply.started":"2022-07-05T00:02:18.046681Z","shell.execute_reply":"2022-07-05T00:04:25.563064Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Max length of Sentences:\", max([len(x.split()) for x in final_data['Sentence']]))\nprint(\"Min length of Sentences:\", min([len(x.split()) for x in final_data['Sentence']]))","metadata":{"execution":{"iopub.status.busy":"2022-07-05T01:07:43.694891Z","iopub.execute_input":"2022-07-05T01:07:43.695245Z","iopub.status.idle":"2022-07-05T01:07:43.722646Z","shell.execute_reply.started":"2022-07-05T01:07:43.695214Z","shell.execute_reply":"2022-07-05T01:07:43.721594Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train_bert, X_test_bert, Y_train_bert, Y_test_bert = train_test_split(final_data['Sentence'], final_data['Sentiment'], test_size = 0.25, random_state = 0, shuffle=True)\nprint(X_train_bert.shape,Y_train_bert.shape)\nprint(X_test_bert.shape,Y_test_bert.shape)","metadata":{"execution":{"iopub.status.busy":"2022-07-05T01:07:45.152529Z","iopub.execute_input":"2022-07-05T01:07:45.152897Z","iopub.status.idle":"2022-07-05T01:07:45.163657Z","shell.execute_reply.started":"2022-07-05T01:07:45.152853Z","shell.execute_reply":"2022-07-05T01:07:45.162394Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_bert_train_final = bert_tokenizer(\n    text=X_train_bert.tolist(),\n    add_special_tokens=True,\n    max_length=50,\n    truncation=True,\n    padding=True,\n    return_tensors='tf',\n    return_token_type_ids=False,\n    return_attention_mask=True,\n    verbose=True\n)\n\nX_bert_train_final['input_ids'].shape","metadata":{"execution":{"iopub.status.busy":"2022-07-05T01:13:19.23128Z","iopub.execute_input":"2022-07-05T01:13:19.23164Z","iopub.status.idle":"2022-07-05T01:13:19.765585Z","shell.execute_reply.started":"2022-07-05T01:13:19.231609Z","shell.execute_reply":"2022-07-05T01:13:19.764608Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_bert_train_final.keys()","metadata":{"execution":{"iopub.status.busy":"2022-07-05T01:13:20.416968Z","iopub.execute_input":"2022-07-05T01:13:20.417896Z","iopub.status.idle":"2022-07-05T01:13:20.425781Z","shell.execute_reply.started":"2022-07-05T01:13:20.417845Z","shell.execute_reply":"2022-07-05T01:13:20.424821Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Y_bert_test_final = pd.get_dummies(Y_test_bert).values\nY_bert_train_final = pd.get_dummies(Y_train_bert).values\nY_bert_train_final.shape, Y_bert_test_final.shape","metadata":{"execution":{"iopub.status.busy":"2022-07-05T01:13:21.075064Z","iopub.execute_input":"2022-07-05T01:13:21.076834Z","iopub.status.idle":"2022-07-05T01:13:21.086555Z","shell.execute_reply.started":"2022-07-05T01:13:21.076783Z","shell.execute_reply":"2022-07-05T01:13:21.085486Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Y_train_bert.value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-07-05T01:13:21.67595Z","iopub.execute_input":"2022-07-05T01:13:21.676848Z","iopub.status.idle":"2022-07-05T01:13:21.685008Z","shell.execute_reply.started":"2022-07-05T01:13:21.676803Z","shell.execute_reply":"2022-07-05T01:13:21.683909Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 5.2) Build Model","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras.initializers import TruncatedNormal\nfrom tensorflow.keras.losses import CategoricalCrossentropy, BinaryCrossentropy\nfrom tensorflow.keras.metrics import CategoricalAccuracy, BinaryAccuracy\nfrom tensorflow.keras.utils import to_categorical, plot_model\nfrom tensorflow.keras.layers import Input, Dense\nfrom tensorflow.keras.callbacks import ModelCheckpoint\nimport tensorflow as tf\n\nimport tensorflow_hub as hub","metadata":{"execution":{"iopub.status.busy":"2022-07-05T01:13:23.987866Z","iopub.execute_input":"2022-07-05T01:13:23.988545Z","iopub.status.idle":"2022-07-05T01:13:23.995221Z","shell.execute_reply.started":"2022-07-05T01:13:23.988494Z","shell.execute_reply":"2022-07-05T01:13:23.99385Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"MAX_LENGTH = 50\nINPUT_IDs = Input(shape=(MAX_LENGTH,), dtype=tf.int32, name=\"input_ids\")\nINPUT_MASK = Input(shape=(MAX_LENGTH,), dtype=tf.int32, name=\"attention_mask\")","metadata":{"execution":{"iopub.status.busy":"2022-07-05T01:13:25.331796Z","iopub.execute_input":"2022-07-05T01:13:25.332264Z","iopub.status.idle":"2022-07-05T01:13:25.340431Z","shell.execute_reply.started":"2022-07-05T01:13:25.332229Z","shell.execute_reply":"2022-07-05T01:13:25.338756Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"embeddings = bert_model([INPUT_IDs, INPUT_MASK])[1] # 0 is hidden state, 1 is pooler_output\n# shape of hidden state is (None, MAX_LENGTH, 1024) ==> out = tf.keras.layers.GlobalMaxPool1D(0.1)(embeddings)\n# shape of booled output is (None, 1024) ==> out = tf.keras.layers.Dropout(0.1)(embeddings)\n\nout = tf.keras.layers.Dropout(0.2)(embeddings)\nout = Dense(64, activation=\"relu\")(out)\nout = tf.keras.layers.Dropout(0.2)(out)\nout = Dense(32, activation=\"relu\")(out)\n\ny = Dense(3, activation='softmax')(out)\nmodel = tf.keras.Model(inputs=[INPUT_IDs, INPUT_MASK], outputs=y)\nmodel.layers[2].trainable = True\n\nmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2022-07-05T01:20:16.876905Z","iopub.execute_input":"2022-07-05T01:20:16.877318Z","iopub.status.idle":"2022-07-05T01:20:19.757666Z","shell.execute_reply.started":"2022-07-05T01:20:16.87728Z","shell.execute_reply":"2022-07-05T01:20:19.756445Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2022-07-05T01:20:19.904523Z","iopub.execute_input":"2022-07-05T01:20:19.905229Z","iopub.status.idle":"2022-07-05T01:20:19.939735Z","shell.execute_reply.started":"2022-07-05T01:20:19.905194Z","shell.execute_reply":"2022-07-05T01:20:19.93861Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# fit model\nbert_history = model.fit(\n    x={'input_ids': X_bert_train_final[\"input_ids\"], 'attention_mask': X_bert_train_final[\"attention_mask\"]},\n    y=Y_bert_train_final,\n    validation_split=0.15,\n    epochs=5,\n    batch_size=24\n)","metadata":{"execution":{"iopub.status.busy":"2022-07-05T01:20:21.671629Z","iopub.execute_input":"2022-07-05T01:20:21.672821Z","iopub.status.idle":"2022-07-05T01:32:14.481026Z","shell.execute_reply.started":"2022-07-05T01:20:21.672777Z","shell.execute_reply":"2022-07-05T01:32:14.479994Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_test_bert_final = bert_tokenizer(\n    text=X_test_bert.tolist(),\n    add_special_tokens=True,\n    max_length=50,\n    truncation=True,\n    padding=True,\n    return_tensors='tf',\n    return_token_type_ids=False,\n    return_attention_mask=True,\n    verbose=True\n)","metadata":{"execution":{"iopub.status.busy":"2022-07-05T01:32:14.483675Z","iopub.execute_input":"2022-07-05T01:32:14.484243Z","iopub.status.idle":"2022-07-05T01:32:14.651832Z","shell.execute_reply.started":"2022-07-05T01:32:14.484202Z","shell.execute_reply":"2022-07-05T01:32:14.650761Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"prediction = model.predict(\n    x={'input_ids':X_test_bert_final[\"input_ids\"], 'attention_mask':X_test_bert_final[\"attention_mask\"]}\n)","metadata":{"execution":{"iopub.status.busy":"2022-07-05T01:32:14.653044Z","iopub.execute_input":"2022-07-05T01:32:14.6534Z","iopub.status.idle":"2022-07-05T01:32:35.946708Z","shell.execute_reply.started":"2022-07-05T01:32:14.653364Z","shell.execute_reply":"2022-07-05T01:32:35.945681Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"prediction.shape","metadata":{"execution":{"iopub.status.busy":"2022-07-04T23:08:39.673825Z","iopub.execute_input":"2022-07-04T23:08:39.6741Z","iopub.status.idle":"2022-07-04T23:08:39.683397Z","shell.execute_reply.started":"2022-07-04T23:08:39.674075Z","shell.execute_reply":"2022-07-04T23:08:39.682245Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = []\nfor i in range(len(prediction)):\n    y_pred.append(tf.one_hot(tf.argmax(prediction[i]), 3)) \ny_pred = np.array(y_pred)","metadata":{"execution":{"iopub.status.busy":"2022-07-04T23:12:17.083944Z","iopub.execute_input":"2022-07-04T23:12:17.084296Z","iopub.status.idle":"2022-07-04T23:12:17.967805Z","shell.execute_reply.started":"2022-07-04T23:12:17.084256Z","shell.execute_reply":"2022-07-04T23:12:17.966793Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred[:3]","metadata":{"execution":{"iopub.status.busy":"2022-07-04T23:12:19.937989Z","iopub.execute_input":"2022-07-04T23:12:19.938623Z","iopub.status.idle":"2022-07-04T23:12:19.947852Z","shell.execute_reply.started":"2022-07-04T23:12:19.938589Z","shell.execute_reply":"2022-07-04T23:12:19.946708Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix, accuracy_score\n\naccuracy_score(Y_bert_test_final, y_pred)","metadata":{"execution":{"iopub.status.busy":"2022-07-04T23:11:32.151438Z","iopub.execute_input":"2022-07-04T23:11:32.152347Z","iopub.status.idle":"2022-07-04T23:11:32.310512Z","shell.execute_reply.started":"2022-07-04T23:11:32.15231Z","shell.execute_reply":"2022-07-04T23:11:32.309526Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Conclusion","metadata":{}},{"cell_type":"code","source":"nb_acc = nb_score * 100\nrnn_acc = rnn_accuracy[1] * 100\nlstm_acc = lstm_accuracy[1] * 100\ngru_acc = gru_accuracy[1] * 100","metadata":{"execution":{"iopub.status.busy":"2022-07-05T02:17:03.264751Z","iopub.execute_input":"2022-07-05T02:17:03.265112Z","iopub.status.idle":"2022-07-05T02:17:03.270584Z","shell.execute_reply.started":"2022-07-05T02:17:03.265079Z","shell.execute_reply":"2022-07-05T02:17:03.269409Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import seaborn as sns\nmethods = [\"Naive Bayes\",\"RNN\", \"LSTM\", \"GRU\"]\naccuracy = [nb_acc, rnn_acc, lstm_acc, gru_acc]\n\nsns.set()\nplt.figure(figsize=(12,6))\nplt.title(\"Models Summary\")\nplt.ylabel(\"Testing Accuracy %\")\nplt.xlabel(\"Model\")\nsns.barplot(x=methods, y=accuracy, palette=\"deep\")\n\nfor idx, method in enumerate(methods):\n    plt.text(idx -0.1, accuracy[idx]+0.02, \"{:.2f}%\".format(accuracy[idx]))\n    \nplt.tight_layout()","metadata":{"execution":{"iopub.status.busy":"2022-07-05T02:19:34.092059Z","iopub.execute_input":"2022-07-05T02:19:34.09279Z","iopub.status.idle":"2022-07-05T02:19:34.36686Z","shell.execute_reply.started":"2022-07-05T02:19:34.092751Z","shell.execute_reply":"2022-07-05T02:19:34.365604Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> As shown, GRU and LSTM got the highest accuracy score","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}