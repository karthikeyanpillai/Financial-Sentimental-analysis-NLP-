{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2340ecde",
   "metadata": {},
   "source": [
    "# EDA(Exploratory Data Analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6df3f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from mlxtend.plotting import scatterplotmatrix\n",
    "import numpy as np\n",
    "from mlxtend.plotting import heatmap\n",
    "from PIL import Image\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "from textblob import TextBlob\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a1a3b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read The File\n",
    "df = pd.read_csv('financial_data_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94fd1bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e019321e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pie chart\n",
    "colors = ['#4F6272', '#B7C3F3', '#DD7596']\n",
    "fig, (ax1) = plt.subplots(ncols=1, figsize=(10, 5))\n",
    "df.Sentiment.value_counts().head(3).plot(kind='pie', labels=None, autopct='%.2f', ax=ax1, wedgeprops = { 'linewidth' : 1, 'edgecolor' : 'white' }, colors=colors).legend(labels={\n",
    "                     \"neutral\",\n",
    "                     \"positive\",\n",
    "                     \"negative\"})\n",
    "central_circle = plt.Circle((0, 0), 0.4, color='white')\n",
    "fig = plt.gcf()\n",
    "fig.gca().add_artist(central_circle)\n",
    "plt.rc('font', size=12)\n",
    "plt.title('% of sentimets', size=15)\n",
    "plt.tight_layout()\n",
    "plt.savefig('images/donut_chart.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907e0a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Polarity scores\n",
    "df[\"Polarity\"] = df[\"Sentence\"].map(lambda Text: TextBlob(Text).sentiment.polarity)\n",
    "df[\"Polarity\"].plot(kind = \"hist\", bins = 15, linewidth = 1, color = \"salmon\", figsize = (10,5))\n",
    "\n",
    "plt.title(\"Polarity Score in Reviews\", pad = 15)\n",
    "plt.xlabel(\"Polarity\", labelpad = 15)\n",
    "\n",
    "plt.ylabel(\"Amount of Reviews\", labelpad = 15)\n",
    "plt.savefig('images/polarity_score.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01730f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Length of reviews\n",
    "df[\"Length\"] = df[\"Sentence\"].astype(str).apply(len)\n",
    "df[\"Length\"].plot(kind = \"hist\", bins = 15, linewidth = 1, color = \"teal\", figsize = (10,5))\n",
    "plt.title(\"Length of Reviews\", pad = 20)\n",
    "plt.xlabel(\"Length\", labelpad = 15)\n",
    "plt.ylabel(\"Amount of Reviews\",labelpad = 20)\n",
    "plt.savefig('images/length_of_reviews.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3ceab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Word counts\n",
    "df[\"Word Counts\"] = df[\"Sentence\"].apply(lambda x: len(str(x).split()))\n",
    "df[\"Word Counts\"].plot(kind = \"hist\", bins = 15, linewidth = 1, color = \"plum\", figsize = (10,5))\n",
    "plt.title(\"Word Counts in Reviews\", pad = 20)\n",
    "plt.xlabel(\"Word Counts\", labelpad = 15)\n",
    "plt.ylabel(\"Amount of Reviews\", labelpad = 20)\n",
    "plt.savefig('images/word_counts.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4572c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#WordCloud\n",
    "Stopwords = set(nltk.corpus.stopwords.words(\"english\")) - set([\"not\"])\n",
    "wc= WordCloud(background_color=\"white\",random_state=1, max_words=2000, width = 3000, height = 1500, stopwords = Stopwords).generate(str(df[\"Sentence\"]))\n",
    "wc.generate(text)\n",
    "plt.figure(figsize = (15, 15))\n",
    "plt.imshow(wc, interpolation = \"bilinear\")\n",
    "plt.axis(\"off\")\n",
    "plt.savefig('images/wordcloud.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105a0be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#N-Gram Analysis\n",
    "def Gram_Analysis(Corpus, Gram, N):\n",
    "    \n",
    "  # Vectorizer\n",
    "  Vectorizer = CountVectorizer(stop_words = Stopwords, ngram_range=(Gram,Gram))\n",
    "\n",
    "  # N-Grams Matrix\n",
    "  ngrams = Vectorizer.fit_transform(Corpus)\n",
    "\n",
    "  # N-Grams Frequency\n",
    "  Count = ngrams.sum(axis=0)\n",
    "\n",
    "  # List of Words\n",
    "  words = [(word, Count[0, idx]) for word, idx in Vectorizer.vocabulary_.items()]\n",
    "\n",
    "  # Sort Descending With Key = Count\n",
    "  words = sorted(words, key = lambda x:x[1], reverse = True)\n",
    "    \n",
    "  return words[:N]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7023c08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Unigrams\n",
    "# Finding 2-gram\n",
    "df_positive = df[df[\"Sentiment\"] == \"positive\"].dropna()\n",
    "words_p = Gram_Analysis(df_positive[\"Sentence\"], 2, 5)\n",
    "Bigram = pd.DataFrame(words_p, columns = [\"Words\", \"Counts\"])\n",
    "\n",
    "# Visualization\n",
    "color_p=['#B7C3F3']\n",
    "Bigram.groupby(\"Words\").sum()[\"Counts\"].sort_values().plot(kind = \"barh\", color = color_p, figsize = (10, 5))\n",
    "plt.title(\"2-gram of Reviews with Positive Sentiments\", loc = \"center\", fontsize = 15, pad = 25)\n",
    "plt.xlabel(\"Total Counts\", fontsize = 15, labelpad = 20)\n",
    "plt.xticks(rotation = 0)\n",
    "plt.ylabel(\"Top Words\", fontsize = 15, labelpad = 20)\n",
    "plt.savefig('images/p_2gram.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd69a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding 2-gram\n",
    "df_negative = df[df[\"Sentiment\"] == \"negative\"].dropna()\n",
    "words_n = Gram_Analysis(df_negative[\"Sentence\"], 2, 5)\n",
    "Bigram = pd.DataFrame(words_n, columns = [\"Words\", \"Counts\"])\n",
    "\n",
    "# Visualization\n",
    "color_n = ['#DD7596']\n",
    "Bigram.groupby(\"Words\").sum()[\"Counts\"].sort_values().plot(kind = \"barh\", color = color_n, figsize = (10, 5))\n",
    "plt.title(\"2-gram of Reviews with Negative Sentiments\", loc = \"center\", fontsize = 15, pad = 25)\n",
    "plt.xlabel(\"Total Counts\", fontsize = 15, labelpad = 20)\n",
    "plt.xticks(rotation = 0)\n",
    "plt.ylabel(\"Top Words\", fontsize = 15, labelpad = 20)\n",
    "plt.savefig('images/n_2gram.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b02092",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding 2-gram\n",
    "df_neutral = df[df[\"Sentiment\"] == \"neutral\"].dropna()\n",
    "words_nl = Gram_Analysis(df_neutral[\"Sentence\"], 2, 5)\n",
    "Bigram = pd.DataFrame(words_nl, columns = [\"Words\", \"Counts\"])\n",
    "\n",
    "# Visualization\n",
    "color_nl = ['#4F6272']\n",
    "Bigram.groupby(\"Words\").sum()[\"Counts\"].sort_values().plot(kind = \"barh\", color = color_nl, figsize = (10, 5))\n",
    "plt.title(\"2-gram of Reviews with Neutral Sentiments\", loc = \"center\", fontsize = 15, pad = 25)\n",
    "plt.xlabel(\"Total Counts\", fontsize = 15, labelpad = 20)\n",
    "plt.xticks(rotation = 0)\n",
    "plt.ylabel(\"Top Words\", fontsize = 15, labelpad = 20)\n",
    "plt.savefig('images/nl_2gram.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cca2e650",
   "metadata": {},
   "source": [
    "# Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af953f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d825fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pull the data\n",
    "df = pd.read_csv('financial_data_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbba74c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature Engineering\n",
    "#Encoding Sentiment variable\n",
    "Encoder = LabelEncoder() \n",
    "df[\"Sentiment\"] = Encoder.fit_transform(df[\"Sentiment\"])  \n",
    "df[\"Sentiment\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89be0b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Term Frequency - Inverse Document Frequency (TF-IDF) Vectorizer\n",
    "tfidf = TfidfVectorizer(max_features = 5000, ngram_range = (2, 2))\n",
    "X = tfidf.fit_transform(df[\"Sentence\"])\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ec3795",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['Sentiment']\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae53e295",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Balance the imbalanced dataset\n",
    "Counter(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91bd700",
   "metadata": {},
   "outputs": [],
   "source": [
    "Balancer = SMOTE(random_state = 42)\n",
    "X_final, y_final = Balancer.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf1c3fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(y_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c6c556",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pie chart\n",
    "colors = ['#4F6272', '#B7C3F3', '#DD7596']\n",
    "fig, (ax1) = plt.subplots(ncols=1, figsize=(10, 5))\n",
    "y_final.value_counts().head(3).plot(kind='pie', labels=None, autopct='%.2f', ax=ax1, wedgeprops = { 'linewidth' : 1, 'edgecolor' : 'white' }, colors=colors).legend(labels={\n",
    "                     \"neutral\":\"1\",\n",
    "                     \"positive\":\"2\",\n",
    "                     \"negative\":\"0\"})\n",
    "central_circle = plt.Circle((0, 0), 0.4, color='white')\n",
    "fig = plt.gcf()\n",
    "fig.gca().add_artist(central_circle)\n",
    "plt.rc('font', size=12)\n",
    "plt.title('% of sentimets after resampling', size=15)\n",
    "plt.tight_layout()\n",
    "plt.savefig('images/donut_chart_balanced_data.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "979ef107",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model Selection\n",
    "#Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_final, y_final, test_size = 0.20, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c87bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model building\n",
    "dt = DecisionTreeClassifier()\n",
    "lr = LogisticRegression()\n",
    "SVC = SVC()\n",
    "rf = RandomForestClassifier()\n",
    "Bayes = BernoulliNB()\n",
    "KNN = KNeighborsClassifier()\n",
    "\n",
    "Models = [dt, lr, SVC, rf, Bayes, KNN]\n",
    "Models_Dict = {0: \"Decision Tree\", 1: \"Logistic Regression\", 2: \"SVC\", 3: \"Random Forest\", 4: \"Naive Bayes\", 5: \"K-Neighbors\"}\n",
    "\n",
    "for i, model in enumerate(Models):\n",
    "  print(\"{} Test Accuracy: {}\".format(Models_Dict[i], cross_val_score(model, X, y, cv = 10, scoring = \"accuracy\").mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d56de46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparamater Tuning\n",
    "Param = {\"C\": np.logspace(-4, 4, 50), \"penalty\": ['l1', 'l2']}\n",
    "grid_search = GridSearchCV(estimator = LogisticRegression(random_state = 42), param_grid = Param, scoring = \"accuracy\", cv = 10, verbose = 0, n_jobs = -1)\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "best_accuracy = grid_search.best_score_\n",
    "best_parameters = grid_search.best_params_\n",
    "\n",
    "print(\"Best Accuracy: {:.2f} %\".format(best_accuracy*100))\n",
    "print(\"Best Parameters:\", best_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9420de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Best model\n",
    "Classifier = LogisticRegression(random_state = 42, C = 6866.488450042998, penalty = 'l2')\n",
    "Classifier.fit(X_train, y_train)\n",
    "\n",
    "Prediction = Classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77375f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Metrics\n",
    "accuracy_score(y_test, Prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e234c595",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confusion Matrix\n",
    "ConfusionMatrix = confusion_matrix(y_test, Prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f29a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting Function for Confusion Matrix\n",
    "colors = ['#4F6272', '#B7C3F3', '#DD7596']\n",
    "\n",
    "def plot_cm(cm, classes, title, normalized = False, cmap = plt.cm.BuPu):\n",
    "    plt.imshow(cm, interpolation = \"nearest\", cmap = cmap)\n",
    "    plt.title(title, pad = 20)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "    \n",
    "\n",
    "    if normalized:\n",
    "        cm = cm.astype('float') / cm.sum(axis = 1)[: np.newaxis]\n",
    "        print(\"Normalized Confusion Matrix\")\n",
    "    else:\n",
    "        print(\"Unnormalized Confusion Matrix\")\n",
    "  \n",
    "    threshold = cm.max() / 2\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            plt.text(j, i, cm[i, j], horizontalalignment = \"center\", color = \"white\" if cm[i, j] > threshold else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.xlabel(\"Predicted Label\", labelpad = 20)\n",
    "    plt.ylabel(\"Real Label\", labelpad = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60405ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cm(ConfusionMatrix, classes = [\"Positive\", \"Neutral\", \"Negative\"], title = \"Confusion Matrix of Sentiment Analysis\")\n",
    "plt.tight_layout()\n",
    "plt.savefig('images/confusion_matrix.png', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c22b209",
   "metadata": {},
   "source": [
    "print(classification_report(y_test, Prediction))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b3bf1cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
